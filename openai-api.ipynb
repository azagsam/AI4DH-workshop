{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "140b7f98",
   "metadata": {},
   "source": [
    "# Commercial LLMs: OpenAI\n",
    "\n",
    "The link to the `API KEY` will be sent to participants email addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55ae147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM stands for \"Large Language Model.\" It refers to a type of artificial intelligence model that is designed to understand and generate human language. These models are typically trained on large datasets containing text from various sources, enabling them to learn patterns, grammar, context, and even certain forms of reasoning based on language.\n",
      "\n",
      "Large Language Models, such as OpenAI's GPT (Generative Pre-trained Transformer) series, are used for a wide range of applications, including:\n",
      "\n",
      "1. **Text Generation**: Producing coherent and contextually relevant text based on a given prompt.\n",
      "2. **Translation**: Converting text from one language to another.\n",
      "3. **Summarization**: Condensing long text into shorter summaries while preserving key information.\n",
      "4. **Question Answering**: Responding to questions based on a provided context or knowledge base.\n",
      "5. **Conversational Agents**: Powering chatbots and virtual assistants for interactive dialogue.\n",
      "\n",
      "LLMs leverage deep learning techniques, particularly the transformer architecture, which allows them to process and generate language effectively. The \"large\" in LLM refers to the size of the model, which usually involves hundreds of millions to billions of parameters, leading to enhanced performance on language tasks compared to smaller models.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "API_KEY = \"\"\n",
    "client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is a LLM?\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "message = response.choices[0].message.content\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a62ace8",
   "metadata": {},
   "source": [
    "### Structured outputs with LLMs\n",
    "\n",
    "JSON is one of the most widely used formats in the world for applications to exchange data.\n",
    "\n",
    "Structured Outputs is a feature that ensures the model will always generate responses that adhere to your supplied JSON Schema, so you don't need to worry about the model omitting a required key, or hallucinating an invalid enum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd82a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "\n",
    "API_KEY = \"\"\n",
    "client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "class TranslationCandidates(BaseModel):\n",
    "    original: str\n",
    "    german: str\n",
    "    slovene: str\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a sentence translation system. Translate an English sentence to German and Slovene.\"},\n",
    "        {\"role\": \"user\", \"content\": \"We are going to lunch.\"},\n",
    "    ],\n",
    "    response_format=TranslationCandidates,\n",
    ")\n",
    "\n",
    "event = completion.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbc37a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'original': 'We are going to lunch.', 'german': 'Wir gehen zu Mittagessen.', 'slovene': 'Gremo na kosilo.'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json_dict = json.loads(completion.choices[0].message.content)\n",
    "print(json_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
