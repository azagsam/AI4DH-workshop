{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "140b7f98",
   "metadata": {},
   "source": [
    "# Commercial LLMs: OpenAI\n",
    "\n",
    "The link to the `API KEY` will be sent to participants email addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53f0c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai==2.13.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55ae147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A LLM, or Large Language Model, is a type of artificial intelligence (AI) model designed to understand, generate, and manipulate human language. These models are typically trained on vast amounts of textual data from various sources, enabling them to learn grammar, facts, reasoning abilities, and even some contextual understanding. \n",
      "\n",
      "Some key characteristics of LLMs include:\n",
      "\n",
      "1. **Scale**: LLMs have a very large number of parameters (on the order of millions or even billions), which enables them to capture complex patterns in language.\n",
      "\n",
      "2. **Transfer Learning**: They often utilize transfer learning techniques, where a model is pre-trained on a diverse dataset and then fine-tuned for specific tasks.\n",
      "\n",
      "3. **Applications**: LLMs can be applied in various natural language processing (NLP) tasks, including text generation, translation, summarization, question-answering, sentiment analysis, and more.\n",
      "\n",
      "4. **Architecture**: Many contemporary LLMs are based on transformer architecture, which allows for efficient parallel processing and has been key in achieving state-of-the-art performance in many language tasks.\n",
      "\n",
      "Examples of popular LLMs include OpenAI's GPT (Generative Pre-trained Transformer) series, Google's BERT (Bidirectional Encoder Representations from Transformers), and others. These models have significantly advanced the field of NLP and contributed to the way systems interact with human language.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "API_KEY = \"\"\n",
    "client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is a LLM?\"}\n",
    "  ],\n",
    "  safety_identifier=\"4F#Zqi9B8M!8\"\n",
    ")\n",
    "\n",
    "message = response.choices[0].message.content\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a62ace8",
   "metadata": {},
   "source": [
    "### Structured outputs with LLMs\n",
    "\n",
    "JSON is one of the most widely used formats in the world for applications to exchange data.\n",
    "\n",
    "Structured Outputs is a feature that ensures the model will always generate responses that adhere to your supplied JSON Schema, so you don't need to worry about the model omitting a required key, or hallucinating an invalid enum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd82a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "\n",
    "API_KEY = \"\"\n",
    "client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "class TranslationCandidates(BaseModel):\n",
    "    original: str\n",
    "    german: str\n",
    "    slovene: str\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a sentence translation system. Translate an English sentence to German and Slovene.\"},\n",
    "        {\"role\": \"user\", \"content\": \"We are going to lunch.\"},\n",
    "    ],\n",
    "    response_format=TranslationCandidates,\n",
    ")\n",
    "\n",
    "event = completion.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbc37a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'original': 'We are going to lunch.', 'german': 'Wir gehen zu Mittagessen.', 'slovene': 'Gremo na kosilo.'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json_dict = json.loads(completion.choices[0].message.content)\n",
    "print(json_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
