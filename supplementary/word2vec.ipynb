{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KJ1wlX6KaDrC"
   },
   "source": [
    "# word2vec\n",
    "\n",
    "In this notebook, we are going to download a small word2vec model and try out some applications of the trained word embeddings.\n",
    "\n",
    "To get started, run the cells of the first section below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4vhIoUEKu_O"
   },
   "source": [
    "## Loading a pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9844,
     "status": "ok",
     "timestamp": 1767628503887,
     "user": {
      "displayName": "Aleš Žagar",
      "userId": "12295379642849833230"
     },
     "user_tz": -60
    },
    "id": "mX21_qaIPg5E",
    "outputId": "59aaec66-31b2-4465-d033-0241b1e209a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
      "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: gensim\n",
      "Successfully installed gensim-4.4.0\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3086,
     "status": "ok",
     "timestamp": 1767628516124,
     "user": {
      "displayName": "Aleš Žagar",
      "userId": "12295379642849833230"
     },
     "user_tz": -60
    },
    "id": "8s8oEqOcPvN5"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t4OWKz7pT_EW",
    "outputId": "239afe51-17f7-4869-913e-d48738b6476a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-05 15:55:48 URL:https://zenodo.org/records/6542975/files/wiki_300_50_word2vec.model?download=1 [29406039/29406039] -> \"wiki_300_50_word2vec.model\" [1]\n",
      "2026-01-05 16:00:06 URL:https://zenodo.org/records/6542975/files/wiki_300_50_word2vec.model.syn1neg.npy?download=1 [995376128/995376128] -> \"wiki_300_50_word2vec.model.syn1neg.npy\" [1]\n"
     ]
    }
   ],
   "source": [
    "# Download the model files from a URL\n",
    "!wget -c -nv 'https://zenodo.org/records/6542975/files/wiki_300_50_word2vec.model?download=1' -O wiki_300_50_word2vec.model\n",
    "!wget -c -nv 'https://zenodo.org/records/6542975/files/wiki_300_50_word2vec.model.syn1neg.npy?download=1' -O wiki_300_50_word2vec.model.syn1neg.npy\n",
    "!wget -c -nv 'https://zenodo.org/records/6542975/files/wiki_300_50_word2vec.model.wv.vectors.npy?download=1' -O wiki_300_50_word2vec.model.wv.vectors.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GgYWH3jOUuVi"
   },
   "outputs": [],
   "source": [
    "# load the model\n",
    "model = KeyedVectors.load('wiki_300_50_word2vec.model')\n",
    "\n",
    "# If we do not plan to train the model further\n",
    "# we can speed up the vector retrieval by only keeping the vectors:\n",
    "vectors = model.wv\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bXMhSGvaOGR"
   },
   "source": [
    "## Finding similar words\n",
    "\n",
    "For example, we can use a vector of a word to find similar words by finding the vector's **nearest neighbours**. These are found through **cosine similarity**, which is calculated from the angle between vectors.\n",
    "\n",
    "<div>\n",
    "<img src=\"https://kdb.ai/files/2024/01/similarity-768x348.png\" width=\"400px\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44RWk7VSKk7e"
   },
   "source": [
    "Find the most similar vectors of the word 'europe':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 857,
     "status": "ok",
     "timestamp": 1726646939692,
     "user": {
      "displayName": "Mojca Brglez",
      "userId": "11572068353057425528"
     },
     "user_tz": -120
    },
    "id": "bzfeFC-KYC0x",
    "outputId": "07e28f7a-e5a1-4f42-ec96-b62a97e4a2fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('asia', 0.701633870601654),\n",
       " ('scandinavia', 0.6125940084457397),\n",
       " ('america', 0.5918585062026978),\n",
       " ('european', 0.5871455073356628),\n",
       " ('africa', 0.5690851807594299),\n",
       " ('southeast_asia', 0.5615699291229248),\n",
       " ('oceania', 0.5580213069915771),\n",
       " ('continent', 0.5538219809532166)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this finds the 8 most similar words and the corresponding cosine similarity\n",
    "vectors.most_similar('europe',topn=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69z3LFrZNeit"
   },
   "source": [
    "Another way of using vectors and cosine similarity is to find the most similar word among the given list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 247,
     "status": "ok",
     "timestamp": 1726647003287,
     "user": {
      "displayName": "Mojca Brglez",
      "userId": "11572068353057425528"
     },
     "user_tz": -120
    },
    "id": "G-yhGp4lNmt-",
    "outputId": "452b17e4-57ff-4c5d-c024-6e44c6bb34d9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'euro'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.most_similar_to_given('europe',['dinar','euro','dollar','pound','krona'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XEOjbmEAM-VX"
   },
   "source": [
    "**Exercise:**\n",
    "\n",
    "Try it out on other words!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 284,
     "status": "ok",
     "timestamp": 1726647033161,
     "user": {
      "displayName": "Mojca Brglez",
      "userId": "11572068353057425528"
     },
     "user_tz": -120
    },
    "id": "B-zagRXUM-yZ",
    "outputId": "2fb93cd4-df25-4490-fe41-3d9c5552df06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('phrase', 0.7247493863105774), ('words', 0.7070206999778748), ('meaning', 0.6717065572738647), ('loanword', 0.6272196173667908), ('colloquial', 0.59702467918396), ('noun', 0.5963165163993835), ('calque', 0.5881631970405579), ('proverb', 0.5685657262802124)]\n",
      "phrase\n"
     ]
    }
   ],
   "source": [
    "print(vectors.most_similar('word',topn=8))\n",
    "print(vectors.most_similar_to_given('word',['phrase','sentence','saying']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 275,
     "status": "ok",
     "timestamp": 1726647199155,
     "user": {
      "displayName": "Mojca Brglez",
      "userId": "11572068353057425528"
     },
     "user_tz": -120
    },
    "id": "q_VbMkofL6qP",
    "outputId": "e6aac2d7-9b2c-45f5-b816-c3dd02d6ae7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19567843"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.similarity('orange','phone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDlQd5VyKNhQ"
   },
   "source": [
    "## Finding outliers\n",
    "\n",
    "We can also use vectors to filter out 'outliers', i.e. words most divergent from the set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 383,
     "status": "ok",
     "timestamp": 1726647298349,
     "user": {
      "displayName": "Mojca Brglez",
      "userId": "11572068353057425528"
     },
     "user_tz": -120
    },
    "id": "SlEJJoDiKWgj",
    "outputId": "ef9af19a-4f6c-4b53-9d31-807b727a0d64"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'tree'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.doesnt_match(['lemon','plum','pear','tree'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZ7_TJGfMi5H"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "grFFtJVZMi22"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjZca_hYMDhC"
   },
   "source": [
    "## Compositionality\n",
    "\n",
    "In some cases, we can also just sum two word vectors to come to a joint concept:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "geIIf-8A2ow2"
   },
   "outputs": [],
   "source": [
    "vectors.most_similar(positive=['yugoslavia','currency'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VIcD47hIMZiC"
   },
   "source": [
    "Try to find another concept for which the compositionality/addition principle holds in vector space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZxqwgZ_6MYY0"
   },
   "outputs": [],
   "source": [
    "vectors.most_similar(positive=['word1','word2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbbHJdMJaSj6"
   },
   "source": [
    "## Word analogies\n",
    "Vectors also allow us to do mathematical operations on words (or their embeddings) that correspond to analogical relations between words.\n",
    "\n",
    "<table style=\"width: 100%; table-layout: fixed;\">\n",
    "  <colgroup>\n",
    "    <col span=\"1\" style=\"width: 400px;\">\n",
    "    <col span=\"1\" style=\"width: 200px;\">\n",
    "  </colgroup>\n",
    "  <tr>\n",
    "    <td>\n",
    "      <p>\n",
    "       For example, we can look for a word that would solve the equation </br>\n",
    "</br>\n",
    "\n",
    " `king - man + woman = x `\n",
    "</br></br>\n",
    "\n",
    " In other words, what is to *king* as *woman* is to *man* </br>\n",
    " OR </br> what is to *woman* as *king* is to *man*?\n",
    "      </p>\n",
    "    </td>\n",
    "    <td>\n",
    "      <img src=\"https://ai.engin.umich.edu/wp-content/uploads/sites/8/2020/06/king-queen.png\" width=300px />\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0Q32sM1TSr1"
   },
   "source": [
    "### Semantic analogies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TM_CG9z9Lo4D"
   },
   "source": [
    "> If a *king* was not a *man* but a *woman*, what would they be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 287,
     "status": "ok",
     "timestamp": 1726647352418,
     "user": {
      "displayName": "Mojca Brglez",
      "userId": "11572068353057425528"
     },
     "user_tz": -120
    },
    "id": "2DAhle9IZ7rB",
    "outputId": "373601b4-c359-4956-a475-d39659aebcd0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.584174633026123),\n",
       " ('queen_consort', 0.5550029873847961),\n",
       " ('queen_dowager', 0.5135421752929688),\n",
       " ('catherine_jagiellon', 0.5011864304542542),\n",
       " ('queen_regnant', 0.5006860494613647),\n",
       " ('regent', 0.49817225337028503),\n",
       " ('gunilla_bielke', 0.49682119488716125),\n",
       " ('princess', 0.4963575601577759),\n",
       " ('jagellon', 0.4916633367538452),\n",
       " ('queen_saovabha_phongsri', 0.4906517565250397)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the vectors for 'king' and 'woman' are added and 'man' is subtracted\n",
    "vectors.most_similar(positive=['king','woman'],negative='man')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y47JS9xuRPk6"
   },
   "source": [
    "> If a *carnivore* didn't eat *meat* but ate *vegetables*, what would they be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 288,
     "status": "ok",
     "timestamp": 1726647404955,
     "user": {
      "displayName": "Mojca Brglez",
      "userId": "11572068353057425528"
     },
     "user_tz": -120
    },
    "id": "_-bVGgeCaDyw",
    "outputId": "edc3fe34-529c-42fa-b625-29a60bcaa8ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('herbivore', 0.5727195143699646),\n",
       " ('carnivorous', 0.5675762295722961),\n",
       " ('herbivores', 0.5299584865570068),\n",
       " ('herbivorous', 0.5283064842224121),\n",
       " ('invertebrate', 0.5204532742500305),\n",
       " ('dicotyledonous', 0.517408549785614),\n",
       " ('salvinia_molesta', 0.513854444026947),\n",
       " ('earthworms', 0.5121837854385376),\n",
       " ('herbaceous', 0.5119017958641052),\n",
       " ('single_celled_organism', 0.5048058032989502)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.most_similar(positive=['carnivore','vegetable'], negative='meat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b33_jFBdTXKa"
   },
   "source": [
    "### Syntactic analogies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aa3vOsq0LycU"
   },
   "source": [
    "We can also compute syntactic analogies, i.e. transfer the syntactic relation between two words to other words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGArFMClRxnL"
   },
   "source": [
    "> If *was* is a form of *be*, what would correspond to the same form of *see*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vu1-8chfdFm7"
   },
   "outputs": [],
   "source": [
    "vectors.most_similar(positive=['was','see'], negative='be')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RihYFvkmSQVQ"
   },
   "source": [
    "> If *spiders* is the plural of *spider*, what would be the plural of *octopus*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O4Mcvl6nTd42"
   },
   "outputs": [],
   "source": [
    "vectors.most_similar(positive=['spiders','octopus'], negative='spider')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6alfds9AZ44p"
   },
   "source": [
    "# Word vectors equipped with POS tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F6l_dHJgTrEM"
   },
   "source": [
    "Word vectors can also be trained on lemmatized data and/or by differentiating different parts of speech. This can prove very useful in disambiguating homographs, e.g. the adjective *second* (place) from the noun *second* (vs minute)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CoWpQkqQ8BFv"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import gensim\n",
    "from gensim import downloader\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from huggingface_hub import hf_hub_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XJgF1iK2Pryx"
   },
   "outputs": [],
   "source": [
    "# here, we directly download the model from huggingface and load it into gensim\n",
    "model_pos = KeyedVectors.load_word2vec_format(hf_hub_download(repo_id=\"Word2vec/nlpl_0\", filename=\"model.bin\"), binary=True, unicode_errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DqwocxbWVwP6"
   },
   "source": [
    "Observe the difference in the neighbourhoods of the NOUN second and the ADJECTIVE second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IJtsmYlc7Wp4"
   },
   "outputs": [],
   "source": [
    "print(model_pos.most_similar('second_NOUN', topn=3))\n",
    "print(model_pos.most_similar('second_ADJ', topn=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYj37LkW7wcO"
   },
   "source": [
    "# Extra: Training your own model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p3yF_Mp_8NLT"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import gensim\n",
    "from gensim import downloader\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from huggingface_hub import hf_hub_download\n",
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim import logging\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CW2-irJtcU6-"
   },
   "outputs": [],
   "source": [
    "# here, I am loading a dataset of historical quotes to represent my training data.\n",
    "!wget -c \"https://huggingface.co/datasets/m-ric/english_historical_quotes/resolve/main/english_historical_quotes.json?download=true\" -O dataset.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TYYQEh5DdHW0"
   },
   "outputs": [],
   "source": [
    "with open('dataset.json','r', encoding='utf-8') as f:\n",
    "    dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fFrlRcULWD22"
   },
   "source": [
    "Let's print out some data from the `dataset` variable to see how it is structured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "psdelMNlefIs"
   },
   "outputs": [],
   "source": [
    "print(len(dataset)) # print out the length of the variable\n",
    "print(type(dataset)) # print out the type of the variable\n",
    "\n",
    "\n",
    "print(dataset[0]) # print out the first item of the list\n",
    "print(dataset[0].keys())  # print out the keys of the first (dictionary) item of the list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8v1mWvBaWNHW"
   },
   "source": [
    "Here, we collect all the sentences contained under the key 'quote' in each item from the `dataset` list.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I3fvdh5eeyom"
   },
   "outputs": [],
   "source": [
    "all_quotes = []\n",
    "for quote in dataset:\n",
    "    all_quotes.append(quote['quote'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7MRHssg7Zkek"
   },
   "source": [
    "Word2vec expects the **input** to be **a tokenized sentence**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZQhYbgSXdGh"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Below, we define our own iterator to return one sentence per pass from our list of `all_quotes`. We also apply additional preprocessing with the built-in `simple_preprocess ` utility which lowercases and tokenizes all the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8vzVYIrYgDis"
   },
   "outputs": [],
   "source": [
    "class MyCorpus:\n",
    "    \"\"\"An iterator that yields sentences (lists of strings).\"\"\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        for line in all_quotes:\n",
    "            yield utils.simple_preprocess(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "olOrOOrRZYVD"
   },
   "source": [
    "When training a model, we can define the following parameters (among many, many others):\n",
    "\n",
    "*  **`vector_size `** – Dimensionality of the word vectors: for word2vec, 100-300 is usually a good choice.\n",
    "\n",
    "*   **`window`**  – Maximum distance between the current and predicted word within a sentence. A larger window will capture more topical semantic information, and a smaller window will capture more syntactic information.\n",
    "\n",
    "\n",
    "*   **`min_count `**   – Ignore all words with total frequency lower than this. We can prune the internal dictionary by disregarding words that appear very rarely. In large corpora, these are usually typos and irrelevant words, and in addition, there’s not enough data to make any meaningful training on those words.\n",
    "\n",
    "\n",
    "\n",
    " *   **`sg`** - Select the training algorithm: 1 for skip-gram; 0 for CBOW (default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UUGJzNeFZW7-"
   },
   "outputs": [],
   "source": [
    "sentences = MyCorpus()\n",
    "model = gensim.models.Word2Vec(sentences=sentences, min_count=1, window=5, vector_size=150, sg=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2pnrAeFZs6Q"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SGz5Yo3FAmPF"
   },
   "source": [
    "### Using your own data\n",
    "\n",
    "If you want to use a dataset from texts directly from a file, you can specify that here. For simple text files (.txt), you can use\n",
    "1.    `.read()` : the whole text is read as a contiguous string  \n",
    "2.   `readlines()`: the file is read line-by-line, creating a list of all lines in the file\n",
    "\n",
    "\n",
    "In case of other formats, you will have to apply preprocessing and text extraction with other dedicated tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xgzPPavE_7q2"
   },
   "outputs": [],
   "source": [
    "# @title Opening a file\n",
    "# if using a location on Google Drive, you need to mount it first:\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# if using files directly from the runtime, you can open them without mounting Drive.\n",
    "\n",
    "# define where the file is\n",
    "\n",
    "filepath = 'drive/MyDrive/path_to_file.txt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HsJv5L7yfBDP"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "\n",
    "The sentences iterable can be simply a list of lists of tokens (Option 1), but for larger corpora, it is smart to create an iterable that streams the sentences directly from disk/network (Option 2).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C8FA_WJDbcfi"
   },
   "outputs": [],
   "source": [
    "# @title Option 1\n",
    "\n",
    "# simple list of lists: sentences are lowercased and split into tokens by space ' '\n",
    "\n",
    "#open and read the file\n",
    "with open(filepath,'r', encoding='utf-8') as f:\n",
    "    custom_data = f.readlines()\n",
    "\n",
    "custom_dataset = [x.lower().split(' ') for x in custom_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FlC2QkPqbT2N"
   },
   "source": [
    "If we have a file containg one sentence per line, we can use the `LineSentence` class which feeds the model one sentence at a time.\n",
    "\n",
    "\n",
    "NB: Words must be already preprocessed; it applies whitespace tokenization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W3P8vaA5Xezl"
   },
   "outputs": [],
   "source": [
    "# @title Option 2\n",
    "\n",
    "# LineSentence class for files with one sentence per line\n",
    "custom_dataset = LineSentence(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BpWNbtSkZ0PM"
   },
   "outputs": [],
   "source": [
    "# @title Train the model with the selected custom dataset.\n",
    "custom_model = gensim.models.Word2Vec(custom_dataset, min_count=2, window=5, vector_size=150, sg=1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "bYj37LkW7wcO"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
